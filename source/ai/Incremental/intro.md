# 增量学习

### 增量基础知识


增量学习的能力就是能够不断地处理现实世界中连续的信息流，在吸收新知识的同时保留甚至整合、优化旧知识的能力。

为什么要增量学习
灾难性遗忘(catastrophic forgetting)
稳定性-可塑性困境(stability-plasticity dilemma)

增量学习和持续学习(Continual Learning)、终身学习(Lifelong Learning)的概念大致是等价的，它们都是在连续的数据流中训练模型，随着时间的推移，更多的数据逐渐可用，同时旧数据可能由于存储限制或隐私保护等原因而逐渐不可用，并且学习任务的类型和数量没有预定义(例如分类任务中的类别数)。

## 增量学习的特点

- 学习新知识的同时能够保留以前学习到的大部分知识，也就是模型在旧任务和新任务上均能表现良好。
- 计算能力与内存应该随着类别数的增加固定或者缓慢增长，最理想的情况是一旦完成某一任务的学习，该任务的观测样本便被全部丢弃。
- 模型可以从新任务和新数据中持续学习新知识，当新任务在不同时间出现，它都是可训练的。

## 增量学习的分类

- 任务增量学习(Task-incremental Learning)
- 难度更高一点的类增量学习(Class-incremental Learning)

## 增量学习的实现方式

三种范式：正则化(regularization)回放(replay)参数隔离(parameter isolation)

### 基于正则化的增量学习

主要思想是「通过给新任务的损失函数施加约束的方法来保护旧知识不被新知识覆盖」，这类方法通常不需要用旧数据来让模型复习已学习的任务，因此是最优雅的一类增量学习方法。Learning without Forgetting (ECCV 2016) 提出的 LwF 算法是基于深度学习的增量学习的里程碑之作，在介绍 LwF 算法之前，我们先了解一些最简单的增量学习方法。

- 微调(Fine-tuning)：微调没有旧任务参数和样本的指导，因此模型在旧任务上的表现几乎一定会变差，也就是发生灾难性遗忘。
- 联合训练(Joint Training)：联合训练相当于在所有已知数据上重新训练模型，效果最好，因此通常被认为是「增量学习的性能上界」，但训练成本太高。
- 特征抽取(Feature Extraction)：特征抽取只训练 ，共享参数没有得到更新，虽然不影响模型在旧任务上的表现，但不能有效捕获新任务独有的特征表示，在新任务上的表现通常不如人意。

LwF 算法是介于联合训练和微调训练之间的训练方式，LwF 的特点是它不需要使用旧任务的数据也能够更新。
LwF 算法的主要思想来自于 knowledge distillation，也就是使新模型在新任务上的预测和旧模型在新任务上的预测相近。

具体来说，LwF 算法先得到旧模型在新任务上的预测值，在损失函数中引入新模型输出的蒸馏损失，然后用微调的方法在新任务上训练模型，从而避免新任务的训练过分调整旧模型的参数而导致新模型在旧任务上性能的下降。

但是，这种方法的缺点是高度依赖于新旧任务之间的相关性，当任务差异太大时会出现任务混淆的现象(inter-task confusion)，并且一个任务的训练时间会随着学习任务的数量线性增长，同时引入的正则项常常不能有效地约束模型在新任务上的优化过程。

不少研究者围绕着 LwF 算法的思想提出了很多改进策略，比较有名的包括 Encoder Based Lifelong Learning (ICCV 2017) 提出的基于低维特征映射的 EBLL 算法，以及 Overcoming catastrophic forgetting in neural networks (PNAS 2017)提出的基于贝叶斯框架的 EWC 算法，EWC 算法实际上对应了一个通用的「参数约束」方法，它引入了一个额外的和参数有关的正则损失：

### 基于回放的增量学习

基本思想就是"温故而知新"，在训练新任务时，一部分具有代表性的旧数据会被保留并用于模型复习曾经学到的旧知识，因此「要保留旧任务的哪部分数据，以及如何利用旧数据与新数据一起训练模型」，就是这类方法需要考虑的主要问题。

iCaRL: Incremental Classifier and Representation Learning (CVPR 2017) 是最经典的基于回放的增量学习模型，iCaRL 的思想实际上和 LwF 比较相似，它同样引入了蒸馏损失来更新模型参数，但又放松了完全不能使用旧数据的限制.

LwF 在训练新数据时完全没用到旧数据，而 iCaRL 在训练新数据时为每个旧任务保留了一部分有代表性的旧数据(iCaRL假设越靠近类别特征均值的样本越有代表性)，因此 iCaRL 能够更好地记忆模型在旧任务上学习到的数据特征。

另外 Experience Replay for Continual Learning (NIPS 2019) 指出这类模型可以动态调整旧数据的保留数量，从而避免了 LwF 算法随着任务数量的增大，计算成本线性增长的缺点。基于 iCaRL 算法的一些有影响力的改进算法包括 End-to-End Incremental Learning (ECCV 2018) 和 Large Scale Incremental Learning (CVPR 2019)，这些模型的损失函数均借鉴了知识蒸馏技术，从不同的角度来缓解灾难性遗忘问题，不过灾难性遗忘的问题还远没有被满意地解决。

iCaRL 的增量学习方法会更新旧任务的参数 ，因此很可能会导致模型对保留下来的旧数据产生过拟合，Gradient Episodic Memory for Continual Learning (NIPS 2017) 针对该问题提出了梯度片段记忆算法(GEM)，GEM 只更新新任务的参数而不干扰旧任务的参数，GEM 以不等式约束的方式修正新任务的梯度更新方向，从而希望模型在不增大旧任务的损失的同时尽量最小化新任务的损失值。

GEM方向的后续改进还有 Efficient Lifelong Learning with A-GEM (ICLR 2019) 和 Gradient based sample selection for online continual learning (NIPS 2019)。

另外，也有一些工作将 VAE 和 GAN 的思想引入了增量学习，比如 Variational Continual Learning (ICLR 2018) 指出了增量学习的贝叶斯性质，将在线变分推理和蒙特卡洛采样引入了增量学习，Continual Learning with Deep Generative Replay (NIPS 2017) 通过训练 GAN 来生成旧数据，从而避免了基于回放的方法潜在的数据隐私问题，这本质上相当于用额外的参数间接存储旧数据，但是生成模型本身还没达到很高的水平，这类方法的效果也不尽人意。

总体来说，基于回放的增量学习的主要缺点是需要额外的计算资源和存储空间用于回忆旧知识，当任务种类不断增多时，要么训练成本会变高，要么代表样本的代表性会减弱，同时在实际生产环境中，这种方法还可能存在「数据隐私泄露」的问题。

## 增量学习的应用

目前的增量学习依旧是一个很开放的研究问题，很大程度上还处于理论探索阶段，在很多方面学界都没有达成统一的共识，不少论文给出的结论常常会相互冲突，因此增量学习还没有在细分领域中得到大规模的应用和落地。

目前增量学习的研究主要还是面向计算机视觉，在自然语言处理领域还没有得到太多关注。一个主要原因是目前自然语言处理社区的注意力主要集中在以 BERT 为代表的自监督表示学习上，在大规模预训练模型的推广下，增量学习的应用价值就不是太明显了。

## See also

- [增量学习(Incremental Learning)小综述](https://zhuanlan.zhihu.com/p/353273834)